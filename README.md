# MLX2026 - Using Apple silicon with MLX library

Explorations of using Apple MLX library to duplicate patterns used in AI Makerspace Bootcamps. This repo contains a series of session folders.  When you have cloned this repo to your local machine, you should open the session folder that you want to work on using Cursor or VS Code.  The README.md file in the session folder will contain the instructions for the session.

It is important that the dependencies are different for each session.  After you have opened the session folder with Cursor or VS Code, you should open an integrated terminal and run the `uv sync` command to install the dependencies for the session.  This will result in a .venv folder as well as a uv.lock file.  This means that there will be a different environment for each session folder!

Each session folder should be able to be used independently of the other session folders.  This means that I have often copied contents of a previous session folder.  The goal is to avoid you from having to find code that you need from previous sessions.

## ğŸ“ Repository Structure

```text
MLX2026/
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ Session_01_Introduction_and_Refactoring/
â”‚   â”œâ”€â”€ README.md                    # Session documentation
â”‚   â”œâ”€â”€ pyproject.toml               # Dependencies (mlx-lm, ipykernel)
â”‚   â”œâ”€â”€ uv.lock                      # Locked dependency versions
â”‚   â”œâ”€â”€ setup.ipynb                  # Environment setup & MLX basics
â”‚   â”œâ”€â”€ setup.py                     # Script version of setup notebook
â”‚   â”œâ”€â”€ refactor.ipynb               # Code refactoring tutorial
â”‚   â”œâ”€â”€ refactor.py                  # Refactored modular application
â”‚   â”œâ”€â”€ cache_files/                 # Cached model files (.safetensors)
â”‚   â”‚   â”œâ”€â”€ Qwen3-4B-Instruct-2507-4bit.safetensors
â”‚   â”‚   â””â”€â”€ Meta-Llama-3.1-8B-Instruct-8bit.safetensors
â”‚   â””â”€â”€ utilities/                   # Reusable utility modules
â”‚       â”œâ”€â”€ __init__.py              # Package initialization
â”‚       â”œâ”€â”€ get_model.py             # Model loading (Qwen, GPT-OSS, Llama, Mistral)
â”‚       â”œâ”€â”€ utils.py                 # Response generation & Harmony format
â”‚       â””â”€â”€ create_cache.py          # Prompt caching utilities
â”‚
â”œâ”€â”€ Session_02_Working_with_GPT-OSS_models/
â”‚   â”œâ”€â”€ README.md                    # Session documentation
â”‚   â”œâ”€â”€ pyproject.toml               # Dependencies
â”‚   â”œâ”€â”€ app.py                       # GPT-OSS application
â”‚   â””â”€â”€ utilities/                   # Reusable utility modules
â”‚       â”œâ”€â”€ __init__.py              # Package initialization
â”‚       â”œâ”€â”€ get_model.py             # Model loading utilities
â”‚       â”œâ”€â”€ utils.py                 # Response generation
â”‚       â””â”€â”€ create_cache.py          # Prompt caching
â”‚
â”œâ”€â”€ Session_03_Creating_Simple_Web_Application/
â”‚   â””â”€â”€ (planned)
â”‚
â””â”€â”€ Session_04_Fine_Tuning_Models/
    â””â”€â”€ (planned)
```
